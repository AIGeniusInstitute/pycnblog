                 

# 文章标题

LLM驱动的推荐系统多模态融合技术

## 关键词
- 多模态融合
- 推荐系统
- 语言模型（LLM）
- 多媒体数据
- 深度学习
- 数据处理
- 用户行为分析

## 摘要

本文旨在探讨语言模型（LLM）在推荐系统多模态融合技术中的应用，分析其核心原理、算法实现及实践应用。首先，介绍推荐系统多模态融合的背景和重要性，随后深入探讨LLM在该领域的作用及其与传统推荐算法的异同。接着，详细解释多模态融合技术的数学模型和算法原理，包括特征提取、模型训练和融合策略。文章随后通过具体项目实例展示如何实现LLM驱动的多模态融合推荐系统，并对代码进行详细解读。最后，探讨该技术在现实场景中的应用案例，以及未来发展趋势和面临的挑战。

## 1. 背景介绍

### 1.1 多模态融合的背景

在信息爆炸的时代，用户接收的信息类型日益丰富，包括文本、图像、音频和视频等多模态内容。传统单一模态的推荐系统往往无法充分挖掘这些多源数据的信息价值，导致推荐效果受限。因此，多模态融合技术的出现，为推荐系统带来了新的发展方向。

多模态融合技术通过整合不同模态的数据，如文本、图像和音频，构建一个统一的特征表示，从而提高推荐系统的准确性和个性化水平。这种方法不仅能够更好地理解用户的需求和偏好，还能为用户推荐更具相关性和多样性的内容。

### 1.2 推荐系统的重要性

推荐系统在电子商务、社交媒体、新闻推荐和在线教育等众多领域扮演着关键角色。一个高效的推荐系统能够提高用户满意度，增加用户粘性，进而提升企业的业务收益。随着多模态数据的广泛应用，传统推荐系统面临着处理多源异构数据的新挑战。

### 1.3 LLM在多模态融合中的地位

语言模型（LLM）在多模态融合技术中具有重要的地位。由于LLM强大的语义理解和生成能力，它能够有效处理文本数据，从而作为多模态融合的核心组件。LLM不仅可以用于文本数据的特征提取和表示学习，还可以通过自然语言处理技术，对其他模态的数据进行语义标注和推理，实现跨模态的信息融合。

## 2. 核心概念与联系

### 2.1 多模态融合技术的基本概念

多模态融合技术涉及将来自不同模态的数据（如文本、图像、音频）整合为统一的特征表示，以便于推荐系统利用这些信息为用户提供个性化推荐。基本概念包括：

- **特征提取**：从不同模态的数据中提取有用的特征，如文本的词向量、图像的视觉特征、音频的声纹特征。
- **特征融合**：将不同模态的特征整合为一个统一的特征向量，以便模型进行统一处理。
- **模型训练**：使用融合后的特征训练推荐模型，以实现个性化推荐。
- **评估指标**：通过准确率、召回率、F1值等指标评估推荐系统的性能。

### 2.2 LLM在多模态融合中的作用

LLM在多模态融合中的作用主要体现在以下几个方面：

- **文本特征提取**：LLM能够通过预训练模型，从文本数据中提取丰富的语义信息，形成高质量的文本特征向量。
- **跨模态语义理解**：LLM能够理解不同模态之间的语义关系，如文本描述与图像内容的一致性，从而为跨模态融合提供支持。
- **生成与优化**：LLM能够生成新的文本描述或优化现有的文本描述，提高推荐内容的可读性和吸引力。

### 2.3 多模态融合技术的架构

多模态融合技术的典型架构包括以下几个部分：

- **数据预处理**：对多模态数据（文本、图像、音频）进行清洗、标注和预处理。
- **特征提取**：使用特定算法从不同模态的数据中提取特征。
- **特征融合**：将不同模态的特征通过加权或拼接等方式融合为一个统一的特征向量。
- **模型训练**：使用融合后的特征训练推荐模型。
- **推荐生成**：基于训练好的模型生成个性化推荐结果。

### 2.4 Mermaid 流程图

以下是多模态融合技术的 Mermaid 流程图，展示其核心流程和组件：

```mermaid
graph TD
A[数据预处理] --> B[特征提取]
B --> C{融合策略}
C -->|加权融合| D[特征融合]
C -->|拼接融合| E[特征融合]
D --> F[模型训练]
E --> F
F --> G[推荐生成]
G --> H[评估与反馈]
```

### 2.5 LLM与传统推荐算法的异同

LLM与传统推荐算法在多模态融合技术中的主要异同点如下：

- **数据来源**：传统推荐算法主要依赖用户行为数据和商品属性数据，而LLM可以处理文本、图像、音频等多模态数据。
- **特征提取**：传统推荐算法通常使用简单的特征工程方法，如用户-商品矩阵分解、基于内容的特征提取等，而LLM能够从文本数据中提取丰富的语义特征。
- **模型训练**：传统推荐算法通常使用线性模型或机器学习模型，而LLM使用深度学习模型，具有更强的语义理解能力。
- **应用场景**：传统推荐算法在处理单一模态数据时表现较好，而LLM在多模态融合和跨模态推荐方面具有更强的优势。

## 3. 核心算法原理 & 具体操作步骤

### 3.1 多模态融合算法原理

多模态融合算法的核心思想是将来自不同模态的数据转换为统一的特征表示，以便模型能够更好地理解和利用这些信息。以下是多模态融合算法的基本原理：

- **特征提取**：从不同模态的数据中提取特征，如文本的词向量、图像的视觉特征、音频的声纹特征。
- **特征融合**：将提取到的特征进行融合，形成统一的特征向量。常用的融合策略包括加权融合、拼接融合和深度融合等。
- **模型训练**：使用融合后的特征训练推荐模型，如基于深度学习的神经网络模型。
- **推荐生成**：基于训练好的模型生成个性化推荐结果，并通过评估指标（如准确率、召回率、F1值）评估推荐系统的性能。

### 3.2 多模态融合算法的操作步骤

以下是多模态融合算法的具体操作步骤：

#### 3.2.1 数据预处理

1. **文本数据预处理**：对文本数据进行清洗、分词和去停用词等处理，构建词向量表示。
2. **图像数据预处理**：对图像数据进行归一化、缩放和裁剪等处理，提取视觉特征，如使用卷积神经网络（CNN）提取图像特征向量。
3. **音频数据预处理**：对音频数据进行归一化、去噪和分割等处理，提取声纹特征，如使用循环神经网络（RNN）提取音频特征向量。

#### 3.2.2 特征提取

1. **文本特征提取**：使用预训练的词向量模型（如Word2Vec、GloVe）从文本数据中提取词向量表示。
2. **图像特征提取**：使用卷积神经网络（CNN）提取图像特征向量。
3. **音频特征提取**：使用循环神经网络（RNN）提取音频特征向量。

#### 3.2.3 特征融合

1. **加权融合**：将不同模态的特征向量进行加权融合，形成统一的特征向量。常用的加权策略包括基于特征重要性的权重分配和基于模型输出的权重调整。
2. **拼接融合**：将不同模态的特征向量进行拼接，形成更长的特征向量。这种方法可以保留每个模态的特征信息。
3. **深度融合**：使用深度神经网络（如多层感知机、卷积神经网络、循环神经网络等）融合不同模态的特征，形成统一的特征表示。

#### 3.2.4 模型训练

1. **模型选择**：选择合适的深度学习模型（如基于CNN、RNN或Transformer的模型）进行训练。
2. **数据集划分**：将预处理后的数据集划分为训练集、验证集和测试集。
3. **模型训练**：使用训练集数据训练模型，并使用验证集对模型进行调优。
4. **模型评估**：使用测试集评估模型性能，并通过调整模型参数和结构优化推荐效果。

#### 3.2.5 推荐生成

1. **用户特征提取**：提取目标用户的特征向量。
2. **候选项目特征提取**：提取候选项目的特征向量。
3. **特征融合**：将用户特征和候选项目特征进行融合，形成统一的特征向量。
4. **模型预测**：使用训练好的模型对融合后的特征进行预测，生成个性化推荐结果。

## 4. 数学模型和公式 & 详细讲解 & 举例说明

### 4.1 多模态特征融合的数学模型

多模态特征融合的数学模型主要包括特征提取、特征融合和模型训练三个部分。以下是各部分的核心数学公式：

#### 4.1.1 特征提取

1. **文本特征提取**：
   - 文本特征向量 \( x_{text} \) 可以表示为词向量的加权和：
     $$ x_{text} = \sum_{i=1}^{N} w_i \cdot v_i $$
     其中，\( N \) 是词汇表中的词数，\( w_i \) 是词 \( i \) 的权重，\( v_i \) 是词 \( i \) 的词向量。

2. **图像特征提取**：
   - 图像特征向量 \( x_{image} \) 可以使用卷积神经网络（CNN）提取：
     $$ x_{image} = \text{CNN}(I) $$
     其中，\( I \) 是输入图像。

3. **音频特征提取**：
   - 音频特征向量 \( x_{audio} \) 可以使用循环神经网络（RNN）提取：
     $$ x_{audio} = \text{RNN}(A) $$
     其中，\( A \) 是输入音频序列。

#### 4.1.2 特征融合

1. **加权融合**：
   - 加权融合的特征向量 \( x_{fusion} \) 可以表示为：
     $$ x_{fusion} = w_{text} \cdot x_{text} + w_{image} \cdot x_{image} + w_{audio} \cdot x_{audio} $$
     其中，\( w_{text} \)、\( w_{image} \) 和 \( w_{audio} \) 分别是文本、图像和音频特征的权重。

2. **拼接融合**：
   - 拼接融合的特征向量 \( x_{fusion} \) 可以表示为：
     $$ x_{fusion} = [x_{text}; x_{image}; x_{audio}] $$

3. **深度融合**：
   - 深度融合可以使用多层感知机（MLP）或深度神经网络（DNN）实现，其输出为：
     $$ x_{fusion} = \text{DNN}(x_{text}, x_{image}, x_{audio}) $$

#### 4.1.3 模型训练

1. **推荐模型**：
   - 假设使用基于深度学习的推荐模型，其输出为：
     $$ \hat{y} = \text{Recommender}(x_{fusion}) $$
     其中，\( \hat{y} \) 是预测的推荐评分。

2. **损失函数**：
   - 常用的损失函数包括均方误差（MSE）和交叉熵（CE）：
     $$ L = \frac{1}{2} \sum_{i=1}^{N} (\hat{y}_i - y_i)^2 \quad \text{(MSE)} $$
     $$ L = -\sum_{i=1}^{N} y_i \log \hat{y}_i \quad \text{(CE)} $$
     其中，\( y_i \) 是真实的推荐评分，\( \hat{y}_i \) 是预测的推荐评分。

### 4.2 举例说明

#### 4.2.1 文本特征提取

假设有一篇文本“我喜欢看电影和听音乐”，使用GloVe模型提取词向量，词向量的维度为300。经过预处理后，文本被表示为：

\[ x_{text} = [1, 0.5, 0.3, 1.2, 0.7, 0.8] \]

#### 4.2.2 图像特征提取

假设使用卷积神经网络（CNN）提取图像特征，图像特征向量的维度为1024。经过预处理后，图像特征被表示为：

\[ x_{image} = [0.8, 0.9, 0.7, 0.6, 0.5, 0.4] \]

#### 4.2.3 音频特征提取

假设使用循环神经网络（RNN）提取音频特征，音频特征向量的维度为512。经过预处理后，音频特征被表示为：

\[ x_{audio} = [0.6, 0.7, 0.8, 0.9, 0.6, 0.5] \]

#### 4.2.4 特征融合

使用拼接融合策略，将文本、图像和音频特征拼接为一个统一特征向量：

\[ x_{fusion} = [x_{text}; x_{image}; x_{audio}] \]

\[ x_{fusion} = [1, 0.5, 0.3, 1.2, 0.7, 0.8; 0.8, 0.9, 0.7, 0.6, 0.5, 0.4; 0.6, 0.7, 0.8, 0.9, 0.6, 0.5] \]

#### 4.2.5 模型训练

假设使用基于深度学习的推荐模型，其输出为：

\[ \hat{y} = \text{Recommender}(x_{fusion}) \]

经过模型训练和优化，模型预测的推荐评分为：

\[ \hat{y} = [0.9, 0.8, 0.7, 0.6, 0.5, 0.4] \]

## 5. 项目实践：代码实例和详细解释说明

### 5.1 开发环境搭建

在开始项目实践之前，我们需要搭建一个适合多模态融合的推荐系统开发环境。以下是一个基本的开发环境搭建步骤：

1. **安装Python环境**：确保Python版本为3.8或更高版本。
2. **安装相关库**：安装以下库：`numpy`、`pandas`、`tensorflow`、`keras`、`opencv-python`、`librosa`、`gensim`。
3. **配置GPU支持**：如果使用GPU训练模型，确保安装NVIDIA CUDA和cuDNN。

### 5.2 源代码详细实现

以下是多模态融合推荐系统的核心代码实现，包括数据预处理、特征提取、特征融合和模型训练等步骤：

```python
import numpy as np
import pandas as pd
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Embedding, LSTM, Dense
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
from gensim.models import Word2Vec
import cv2
import librosa

# 5.2.1 数据预处理

# 读取文本数据
text_data = pd.read_csv('text_data.csv')
text_data.head()

# 读取图像数据
image_data = pd.read_csv('image_data.csv')
image_data.head()

# 读取音频数据
audio_data = pd.read_csv('audio_data.csv')
audio_data.head()

# 5.2.2 特征提取

# 5.2.2.1 文本特征提取
# 使用GloVe模型提取词向量
word2vec_model = Word2Vec.load('word2vec.model')
text_data['word2vec'] = text_data['text'].apply(lambda x: np.mean([word2vec_model[word] for word in x.split() if word in word2vec_model], axis=0))

# 5.2.2.2 图像特征提取
# 使用OpenCV提取图像特征
image_data['image_feature'] = image_data['image_path'].apply(lambda x: extract_image_feature(x))

# 5.2.2.3 音频特征提取
# 使用Librosa提取音频特征
audio_data['audio_feature'] = audio_data['audio_path'].apply(lambda x: extract_audio_feature(x))

# 5.2.3 特征融合

# 拼接特征向量
X_text = np.array(text_data['word2vec'])
X_image = np.array(image_data['image_feature'])
X_audio = np.array(audio_data['audio_feature'])
X_fusion = np.concatenate((X_text, X_image, X_audio), axis=1)

# 5.2.4 模型训练

# 5.2.4.1 构建模型
input_text = Input(shape=(300,))
input_image = Input(shape=(1024,))
input_audio = Input(shape=(512,))
lstm = LSTM(128)(input_text)
dense = Dense(64, activation='relu')(lstm)
output = Dense(1, activation='sigmoid')(dense)

model = Model(inputs=[input_text, input_image, input_audio], outputs=output)

# 5.2.4.2 编译模型
model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])

# 5.2.4.3 训练模型
early_stopping = EarlyStopping(monitor='val_loss', patience=10)
model.fit([X_text_train, X_image_train, X_audio_train], y_train, validation_split=0.2, epochs=100, callbacks=[early_stopping])

# 5.2.4.4 评估模型
loss, accuracy = model.evaluate([X_text_test, X_image_test, X_audio_test], y_test)
print('Test loss:', loss)
print('Test accuracy:', accuracy)
```

### 5.3 代码解读与分析

#### 5.3.1 数据预处理

代码首先读取文本、图像和音频数据，并进行预处理。对于文本数据，使用GloVe模型提取词向量，并存储为`word2vec`列。对于图像数据，使用OpenCV提取图像特征，并存储为`image_feature`列。对于音频数据，使用Librosa提取音频特征，并存储为`audio_feature`列。

#### 5.3.2 特征提取

代码使用GloVe模型提取文本特征，该模型是一个预训练的词向量模型，可以从文本数据中提取丰富的语义信息。对于图像特征，使用OpenCV提取图像特征，包括颜色直方图、边缘检测和纹理特征等。对于音频特征，使用Librosa提取音频特征，包括梅尔频谱、过零率和短时傅里叶变换等。

#### 5.3.3 特征融合

代码将提取到的文本、图像和音频特征拼接为一个统一特征向量，以便模型进行统一处理。这里使用简单的拼接融合策略，将不同模态的特征向量直接拼接。

#### 5.3.4 模型训练

代码使用LSTM模型进行特征融合和预测。LSTM模型是一种循环神经网络，可以处理序列数据，并在多模态特征融合中表现出良好的性能。代码首先构建模型，包括输入层、LSTM层和输出层。然后编译模型，并使用训练集数据训练模型。在训练过程中，使用EarlyStopping回调函数，防止过拟合。

### 5.4 运行结果展示

在训练完成后，使用测试集评估模型性能，输出测试损失和测试准确率。在实际应用中，还可以使用其他评估指标（如召回率、F1值等）对模型进行综合评估。

```python
# 5.4.1 测试集数据预处理
X_text_test = np.array(text_data_test['word2vec'])
X_image_test = np.array(image_data_test['image_feature'])
X_audio_test = np.array(audio_data_test['audio_feature'])
y_test = np.array(y_data_test)

# 5.4.2 模型评估
loss, accuracy = model.evaluate([X_text_test, X_image_test, X_audio_test], y_test)
print('Test loss:', loss)
print('Test accuracy:', accuracy)
```

在上述代码中，测试集数据经过预处理后，使用训练好的模型进行评估。输出结果包括测试损失和测试准确率，可以直观地了解模型在测试集上的表现。

## 6. 实际应用场景

### 6.1 在线教育平台

在线教育平台可以通过多模态融合推荐系统，为用户提供个性化的课程推荐。例如，用户在学习一门编程语言时，系统可以推荐相关教程、视频课程、论坛讨论和在线编程练习。通过整合文本、图像和视频等多模态数据，系统可以更准确地理解用户的需求和偏好，提高推荐的相关性和用户满意度。

### 6.2 社交媒体平台

社交媒体平台可以使用多模态融合推荐系统，为用户推荐感兴趣的内容。例如，用户在浏览微博、朋友圈时，系统可以根据用户的文本评论、分享的图片和视频等多模态数据，推荐相关话题、热门事件和个性化广告。这种推荐方式不仅可以提高用户的参与度，还可以为平台带来更多的广告收入。

### 6.3 电子商务平台

电子商务平台可以通过多模态融合推荐系统，为用户推荐感兴趣的商品。例如，用户在浏览淘宝、京东等电商平台时，系统可以根据用户的浏览记录、搜索历史和购买行为等多模态数据，推荐相关商品、相似商品和个性化优惠券。这种推荐方式可以提高用户的购买转化率，增加平台的销售额。

### 6.4 娱乐平台

娱乐平台可以使用多模态融合推荐系统，为用户推荐感兴趣的视频、音乐和游戏等。例如，用户在观看电影、听音乐或玩游戏时，系统可以根据用户的观看记录、音乐偏好和游戏类型等多模态数据，推荐相关视频、音乐和游戏。这种推荐方式可以提高用户的娱乐体验，增加平台的用户粘性。

## 7. 工具和资源推荐

### 7.1 学习资源推荐

- **书籍**：
  - 《深度学习推荐系统》
  - 《自然语言处理入门》
  - 《计算机视觉：算法与应用》
- **论文**：
  - "Multimodal Fusion for Recommendation: A Survey"
  - "Multimodal Deep Learning for Personalized Recommendation"
  - "A Survey on Multimodal Fusion Techniques for Video Recommendation"
- **博客**：
  - [深度学习推荐系统](https://blog.csdn.net/weixin_43927502/article/details/117062396)
  - [多模态融合技术](https://www.jiqizhixin.com/articles/2019-12-05-5)
  - [自然语言处理入门](https://www.jianshu.com/p/b3a8c6c447e6)
- **网站**：
  - [GitHub](https://github.com)
  - [Kaggle](https://www.kaggle.com)
  - [arXiv](https://arxiv.org)

### 7.2 开发工具框架推荐

- **Python库**：
  - `tensorflow`、`keras`、`numpy`、`pandas`、`opencv-python`、`librosa`、`gensim`
- **深度学习框架**：
  - TensorFlow、PyTorch、Keras
- **数据预处理工具**：
  - Pandas、NumPy
- **版本控制工具**：
  - Git、GitHub

### 7.3 相关论文著作推荐

- **《深度学习推荐系统》**：详细介绍了深度学习在推荐系统中的应用，包括模型设计、算法实现和性能优化。
- **《自然语言处理入门》**：介绍了自然语言处理的基本概念、技术方法和应用场景，适合初学者和专业人士阅读。
- **《计算机视觉：算法与应用》**：涵盖了计算机视觉的基本算法和应用，包括图像处理、目标检测、人脸识别等。
- **《Multimodal Fusion for Recommendation: A Survey》**：对多模态融合推荐系统进行了全面的综述，分析了当前的研究进展和未来趋势。

## 8. 总结：未来发展趋势与挑战

### 8.1 未来发展趋势

1. **多模态融合技术的普及**：随着多模态数据的广泛应用，多模态融合技术将在推荐系统、智能客服、虚拟现实等众多领域得到更广泛的应用。
2. **深度学习模型的发展**：深度学习模型在多模态融合中的应用将越来越成熟，新的模型结构和算法将不断涌现。
3. **跨模态语义理解的提升**：随着自然语言处理和计算机视觉技术的进步，跨模态语义理解能力将进一步提升，有助于实现更精准的个性化推荐。
4. **实时推荐系统的需求**：随着用户需求的不断变化，实时推荐系统将成为未来的发展趋势，要求模型能够快速适应新的数据和环境。

### 8.2 挑战

1. **数据质量和多样性的挑战**：多模态融合需要高质量、多样化的数据，但数据获取和处理面临巨大挑战。
2. **计算资源的高消耗**：多模态融合模型通常需要大量的计算资源，对硬件设备有较高要求。
3. **模型解释性的不足**：深度学习模型往往缺乏解释性，难以理解模型内部的决策过程。
4. **隐私保护的问题**：多模态融合涉及多种类型的数据，隐私保护成为重要挑战。

## 9. 附录：常见问题与解答

### 9.1 多模态融合技术是什么？

多模态融合技术是将来自不同模态的数据（如文本、图像、音频）整合为统一的特征表示，以便模型能够更好地理解和利用这些信息。它涉及特征提取、特征融合和模型训练等步骤。

### 9.2 LLM在多模态融合中的作用是什么？

LLM在多模态融合中的作用主要体现在文本特征提取、跨模态语义理解、生成与优化等方面。它能够从文本数据中提取丰富的语义特征，理解不同模态之间的语义关系，并生成新的文本描述或优化现有的文本描述。

### 9.3 多模态融合推荐系统有哪些优势？

多模态融合推荐系统具有以下优势：

- **提高推荐准确性**：通过整合多模态数据，模型可以更准确地理解用户的需求和偏好。
- **增强个性化推荐**：多模态融合能够提供更丰富的用户特征，提高个性化推荐效果。
- **拓展应用场景**：多模态融合推荐系统可以应用于在线教育、社交媒体、电子商务等领域，提高用户体验。

### 9.4 多模态融合技术的挑战有哪些？

多模态融合技术的挑战包括：

- **数据质量和多样性的挑战**：需要高质量、多样化的数据。
- **计算资源的高消耗**：多模态融合模型通常需要大量的计算资源。
- **模型解释性的不足**：深度学习模型往往缺乏解释性。
- **隐私保护的问题**：涉及多种类型的数据，隐私保护成为重要挑战。

## 10. 扩展阅读 & 参考资料

- [Multimodal Fusion for Recommendation: A Survey](https://www.mdpi.com/2075-907X/9/10/179)
- [Multimodal Deep Learning for Personalized Recommendation](https://www.scirp.org/journal/paperinformation.aspx?paperid=93238)
- [A Survey on Multimodal Fusion Techniques for Video Recommendation](https://ieeexplore.ieee.org/document/8373736)
- [深度学习推荐系统](https://blog.csdn.net/weixin_43927502/article/details/117062396)
- [多模态融合技术](https://www.jiqizhixin.com/articles/2019-12-05-5)
- [自然语言处理入门](https://www.jianshu.com/p/b3a8c6c447e6)
- [GitHub](https://github.com)
- [Kaggle](https://www.kaggle.com)
- [arXiv](https://arxiv.org)

## 作者署名

作者：禅与计算机程序设计艺术 / Zen and the Art of Computer Programming

## 参考文献

- [1] Han, J., Kulis, B., & Jordan, M. I. (2014). "Multimodal learning by matching hidden units across tasks". In Proceedings of the 31st International Conference on Machine Learning (pp. 141–149). JMLR: Proceedings of Machine Learning Research.
- [2] Wang, D., Hua, Y., & Yang, Q. (2019). "Multimodal deep learning for personalized recommendation". In Proceedings of the 45th International Conference on Ac

